if [ ! -f "data/corpus.txt" ]; then
	zig run src/sampling.zig -O ReleaseFast
fi

# dataset directory
dataset=data

# text file name; one document per line
text_file=corpus.txt

# category name file; one category per line; each line contains "[category id] [category names]"
category_file=josh_category_names.txt

# taxonomy file; one edge per line; each line contains "[parent id] [child id]"
taxo_file=josh_taxonomy.txt

# taxonomy file in matrix form; generated by read_taxo.py
matrix_file=matrix_josh_taxonomy.txt

# node level information file; generated by read_taxo.py
level_file=level_josh_taxonomy.txt

# if [ ! -f "$dataset/$matrix_file" ] || [ ! -f "$dataset/$level_file" ]; then
    python xxx2vec/josh_read_taxo.py --dataset $dataset --category_file $category_file --taxo_file $taxo_file
# fi

# word embedding dimension
word_dim=200

# local context window size
window_size=5

# minimum word count in corpus; words that appear less than this threshold will be discarded
min_count=5

# number of total iterations to run on the corpus
iter=12

# number of threads to be run in parallel
threads=4

# cd xxx2vec && ./build.sh && cd ..

time zig run xxx2vec/josh.c -O ReleaseFast -- -train ${dataset}/${text_file} \
	-category-file ${dataset}/${category_file} -matrix-file ${dataset}/${matrix_file} -level-file ${dataset}/${level_file} \
	-word-emb ${dataset}/josh_emb.txt -tree-emb ${dataset}/josh_tree_emb.txt \
	-size ${word_dim} -window ${window_size} -sample 1e-3 -word-margin 0.25 -cat-margin 0.9 \
	-alpha 0.025 -tree-period 128 -global-lambda 1.5 -lambda-cat 1.0 -lambda-tree 1.0 -negative 2 \
	-expand 1 -pretrain 2 \
	-min-count ${min_count} -iter ${iter} -threads ${threads} 
